{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@64db79c\n",
       "df: org.apache.spark.sql.DataFrame = [Company: string, Person: string ... 1 more field]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "val df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"/Users/rahul.bhatia/Desktop/scala-training/Sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|  200|\n",
      "|   GOOG|Charlie|  120|\n",
      "|   GOOG|  Frank|  340|\n",
      "|   MSFT|   Tina|  600|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|     FB|   Carl|  870|\n",
      "|     FB|  Sarah|  350|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   GOOG|    3|\n",
      "|     FB|    2|\n",
      "|   MSFT|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|min(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       120|\n",
      "|     FB|       350|\n",
      "|   MSFT|       124|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       340|\n",
      "|     FB|       870|\n",
      "|   MSFT|       600|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   GOOG|       660|\n",
      "|     FB|      1220|\n",
      "|   MSFT|       967|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").min().show()\n",
    "df.groupBy(\"Company\").max().show()\n",
    "df.groupBy(\"Company\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT Company)|\n",
      "+-----------------------+\n",
      "|                      3|\n",
      "+-----------------------+\n",
      "\n",
      "+-------------------+\n",
      "|sum(DISTINCT Sales)|\n",
      "+-------------------+\n",
      "|               2847|\n",
      "+-------------------+\n",
      "\n",
      "+-----------------+\n",
      "|  var_samp(Sales)|\n",
      "+-----------------+\n",
      "|67235.55357142855|\n",
      "+-----------------+\n",
      "\n",
      "+------------------+\n",
      "|stddev_samp(Sales)|\n",
      "+------------------+\n",
      "|259.29819430807567|\n",
      "+------------------+\n",
      "\n",
      "+--------------------+\n",
      "|  collect_set(Sales)|\n",
      "+--------------------+\n",
      "|[350, 340, 870, 1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"Sales\")).show() \n",
    "df.select(sumDistinct(\"Sales\")).show()\n",
    "df.select(variance(\"Sales\")).show()\n",
    "df.select(stddev(\"Sales\")).show() //avg,max,min,sum,stddev\n",
    "df.select(collect_set(\"Sales\")).show() // remove duplicates and collect in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: Array[org.apache.spark.sql.Row] = Array([WrappedArray(350, 340, 870, 120, 243, 124, 600, 200)])\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Retrive value from a DF using .collect()\n",
    "df.select(collect_set(\"Sales\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|  120|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   GOOG|    Sam|  200|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|   GOOG|  Frank|  340|\n",
      "|     FB|  Sarah|  350|\n",
      "|   MSFT|   Tina|  600|\n",
      "|     FB|   Carl|  870|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|  870|\n",
      "|   MSFT|   Tina|  600|\n",
      "|     FB|  Sarah|  350|\n",
      "|   GOOG|  Frank|  340|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|   GOOG|    Sam|  200|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   GOOG|Charlie|  120|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Sort by descending order\n",
    "df.orderBy($\"Sales\".desc).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
